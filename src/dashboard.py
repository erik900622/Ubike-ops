import os
import sys
import datetime

import pandas as pd
import pydeck as pdk
import plotly.express as px
import streamlit as st
from sqlalchemy import text  # âœ… æ–°å¢

# è®“ Python æ‰¾åˆ° src package
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from src.analysis import get_current_status, find_high_risk_stations
from src.config import RISK_THRESHOLD_EMPTY, RISK_THRESHOLD_FULL
from src.database import get_latest_collection_time, get_engine


# -----------------------------
# Cacheï¼šæœ€æ–° snapshot
# -----------------------------
@st.cache_data(ttl=60)
def load_current_status():
    return get_current_status()


# -----------------------------
# Flow / Heatmapï¼šæœ€è¿‘ 1 å¤© 06â€“22
# -----------------------------
@st.cache_data(ttl=120)
def load_hourly_flow(start_hour: int = 6, end_hour: int = 22) -> pd.DataFrame:
    engine = get_engine()
    dialect = engine.dialect.name  # 'sqlite' or 'postgresql'

    if dialect == "postgresql":
        sql = """
            SELECT
                sarea,
                sno,
                sna,
                EXTRACT(HOUR FROM collection_time::timestamp)::integer AS hour,
                AVG(rent) AS avg_rent,
                AVG(return_count) AS avg_return
            FROM stations_realtime
            WHERE 
                collection_time::timestamp >= NOW() - INTERVAL '1 day'
                AND EXTRACT(HOUR FROM collection_time::timestamp)::integer 
                    BETWEEN %(sh)s AND %(eh)s
            GROUP BY sarea, sno, sna, hour
            ORDER BY sarea, sno, hour
        """
        df = pd.read_sql(sql, engine, params={"sh": start_hour, "eh": end_hour})

    else:
        sql = """
            SELECT
                sarea,
                sno,
                sna,
                CAST(strftime('%H', collection_time) AS INTEGER) AS hour,
                AVG(rent) AS avg_rent,
                AVG(return_count) AS avg_return
            FROM stations_realtime
            WHERE 
                collection_time >= datetime('now', '-1 day', 'localtime')
                AND CAST(strftime('%H', collection_time) AS INTEGER) 
                    BETWEEN :sh AND :eh
            GROUP BY sarea, sno, sna, hour
        """
        df = pd.read_sql(sql, engine, params={"sh": start_hour, "eh": end_hour})

    if df.empty:
        return df

    # ---- capacity & RPI ----
    capacity = df["avg_rent"] + df["avg_return"]
    df["capacity"] = capacity

    df["rpi"] = 0.0
    df["need_bikes"] = 0

    mask = capacity > 0
    df.loc[mask, "rpi"] = (
        (capacity[mask] * 0.5) - df.loc[mask, "avg_rent"]
    ) / capacity[mask]

    df.loc[mask, "need_bikes"] = (
        df.loc[mask, "rpi"] * capacity[mask]
    ).round().astype(int)

    return df


# -----------------------------
# Streamlit Layout è¨­å®š
# -----------------------------
st.set_page_config(page_title="Ubike Operation Dashboard", layout="wide")
st.title("ğŸš² Ubike Operation Optimization System")

# ===== Sidebarï¼šå°èˆª + ç‹€æ…‹ =====
st.sidebar.header("Configuration")

# Snapshot refreshï¼ˆåªæ¸… cacheï¼Œä¸å‹• pageï¼‰
if st.sidebar.button("ğŸ”„ Refresh Snapshot"):
    load_current_status.clear()

# é é¢å°èˆªï¼ˆStyle Bï¼šç”¨ sidebar radioï¼Œç‹€æ…‹æ”¾ session_stateï¼‰
PAGES = [
    "ğŸ—ºï¸ Map View",
    "âš ï¸ High Risk Stations",
    "ğŸ”® Prediction",
    "ğŸ· Station Types",
    "ğŸ“ˆ Flow / Heatmap",
]

default_page = st.session_state.get("active_page", PAGES[0])
page = st.sidebar.radio("é é¢", PAGES, index=PAGES.index(default_page))
st.session_state["active_page"] = page

# DB æœ€æ–° collection_time
latest_ct = get_latest_collection_time()
if latest_ct:
    latest_dt = pd.to_datetime(latest_ct, errors="coerce")
    latest_str = (
        latest_dt.strftime("%Y-%m-%d %H:%M:%S")
        if not pd.isna(latest_dt)
        else str(latest_ct)
    )
else:
    latest_str = "N/A"

st.sidebar.markdown("### ğŸ“¦ DB æœ€æ–°è³‡æ–™æ™‚é–“")
st.sidebar.write(f"**{latest_str}**")

st.sidebar.markdown("### â± ç¾åœ¨æ™‚é–“")
st.sidebar.write(datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))

st.sidebar.markdown("---")
st.sidebar.caption(
    "Snapshot ä¾†è‡ª load_current_status()ï¼›Flow/Heatmap ä½¿ç”¨æœ€è¿‘ 24 å°æ™‚è³‡æ–™ã€‚"
)

# ===== ä¸»è³‡æ–™ï¼ˆsnapshotï¼‰ =====
df = load_current_status()
# ç§»é™¤æ¸¬è©¦å€åŸŸï¼Œé¿å… Test Area å½±éŸ¿æ‰€æœ‰é é¢
df = df[df["sarea"] != "Test Area"].copy()

if df.empty:
    st.error("No data available. Please ensure the collector is running.")
    st.stop()

# Summary æŒ‡æ¨™
total_stations = len(df)
empty_risk, full_risk = find_high_risk_stations(df)

c1, c2, c3 = st.columns(3)
c1.metric("Total Stations", total_stations)
c2.metric("ğŸ”´ Empty Risk Stations", len(empty_risk))
c3.metric("ğŸ”µ Full Risk Stations", len(full_risk))

st.markdown("---")

# ======================================================
# PAGE 1 â€” Map View
# ======================================================
if page == "ğŸ—ºï¸ Map View":
    st.subheader("Station Map (Risk View)")

    sarea_options = ["å…¨éƒ¨å€åŸŸ"] + sorted(df["sarea"].dropna().unique().tolist())
    selected_sarea = st.selectbox("å€åŸŸç¯©é¸", sarea_options, index=0)

    risk_view = st.radio(
        "é¡¯ç¤ºé¡å‹", ["å…¨éƒ¨ç«™", "ç©ºè»Šé¢¨éšª", "æ»¿ç«™é¢¨éšª"], horizontal=True
    )

    if selected_sarea != "å…¨éƒ¨å€åŸŸ":
        map_df = df[df["sarea"] == selected_sarea].copy()
    else:
        map_df = df.copy()

    if map_df.empty:
        st.warning("é€™å€‹å€åŸŸç›®å‰æ²’æœ‰è³‡æ–™ã€‚")
    else:
        map_df = map_df[
            ["lat", "lng", "sna", "rent", "return_count", "sno"]
        ].copy()
        map_df = map_df.rename(columns={"lng": "lon"})

        capacity_map = (map_df["rent"] + map_df["return_count"]).clip(lower=1)
        map_df["empty_ratio"] = 1 - (map_df["rent"] / capacity_map)
        map_df["full_ratio"] = 1 - (map_df["return_count"] / capacity_map)

        if risk_view == "ç©ºè»Šé¢¨éšª":
            map_df = map_df[map_df["rent"] <= RISK_THRESHOLD_EMPTY]
        elif risk_view == "æ»¿ç«™é¢¨éšª":
            map_df = map_df[map_df["return_count"] <= RISK_THRESHOLD_FULL]

        if map_df.empty:
            st.warning("ç›®å‰ç¬¦åˆæ¢ä»¶çš„ç«™é»ç‚º 0ã€‚")
        else:
            color_expr_col = (
                "empty_ratio" if risk_view != "æ»¿ç«™é¢¨éšª" else "full_ratio"
            )

            center_lat = map_df["lat"].mean()
            center_lon = map_df["lon"].mean()

            layer = pdk.Layer(
                "ScatterplotLayer",
                data=map_df,
                get_position="[lon, lat]",
                get_radius=60,
                pickable=True,
                get_fill_color=f"[255 * {color_expr_col}, 100, 150]",
                get_line_color=[0, 0, 0],
            )

            view_state = pdk.ViewState(
                latitude=center_lat,
                longitude=center_lon,
                zoom=12,
                pitch=0,
            )

            deck = pdk.Deck(
                layers=[layer],
                initial_view_state=view_state,
                tooltip={
                    "text": "{sna}\nå¯å€Ÿ: {rent}  å¯é‚„: {return_count}"
                },
            )

            st.pydeck_chart(deck)

# ======================================================
# PAGE 2 â€” High Risk Stations
# ======================================================
elif page == "âš ï¸ High Risk Stations":
    col_empty, col_full = st.columns(2)

    with col_empty:
        st.subheader("ğŸ”´ Empty Risk (Low Bikes)")
        if not empty_risk.empty:
            st.dataframe(
                empty_risk[
                    ["sno", "sna", "rent", "update_time", "collection_time"]
                ]
            )
        else:
            st.success("No empty risk stations.")

    with col_full:
        st.subheader("ğŸ”µ Full Risk (Low Spots)")
        if not full_risk.empty:
            st.dataframe(
                full_risk[
                    [
                        "sno",
                        "sna",
                        "return_count",
                        "update_time",
                        "collection_time",
                    ]
                ]
            )
        else:
            st.success("No full risk stations.")

# ======================================================
# PAGE 3 â€” Prediction
# ======================================================
elif page == "ğŸ”® Prediction":
    st.subheader("Demand Prediction (Trend-Based)")
    st.write("ä½¿ç”¨æœ€è¿‘æ™‚é–“åºåˆ—çš„ç·šæ€§è¶¨å‹¢ï¼Œé æ¸¬æœªä¾† 0â€“60 åˆ†é˜å¯å€Ÿè»Šæ•¸ã€‚")

    station_options = df.apply(
        lambda x: f"{x['sno']} - {x['sna']}", axis=1
    ).tolist()
    selected_station_str = st.selectbox("é¸æ“‡ç«™é»", station_options)

    if selected_station_str:
        sno = selected_station_str.split(" - ")[0]
        from src.prediction import calculate_trend, predict_demand

        slope, current_bikes, capacity_pred, points_used = calculate_trend(
            sno, max_points=30
        )

        col_curr, col_trend, col_cap, col_pts = st.columns(4)
        col_curr.metric("Current Bikes", current_bikes)
        col_trend.metric("Trend (bikes/min)", f"{slope:.2f}")
        col_cap.metric("Capacity", capacity_pred)
        col_pts.metric("Points Used", points_used)

        if points_used < 3:
            st.warning("è³‡æ–™é»å°‘æ–¼ 3 ç­†ï¼Œé æ¸¬æº–åº¦è¼ƒä½ã€‚")

        future_times = []
        predictions = []
        now = datetime.datetime.now()

        for m in range(0, 61, 5):
            future_time = now + datetime.timedelta(minutes=m)
            pred, _info = predict_demand(
                sno, minutes_ahead=m, max_points=30
            )
            future_times.append(future_time.strftime("%H:%M"))
            predictions.append(pred)

        pred_df = pd.DataFrame(
            {"Time": future_times, "Predicted Bikes": predictions}
        )

        fig_pred = px.line(
            pred_df,
            x="Time",
            y="Predicted Bikes",
            markers=True,
        )
        st.plotly_chart(fig_pred, width="stretch")
        st.dataframe(pred_df.set_index("Time"))

# ======================================================
# PAGE 4 â€” Station Types (Clusters)
# ======================================================
elif page == "ğŸ· Station Types":
    st.subheader("Station Clusters (Usage Pattern)")

    try:
        cluster_df = pd.read_csv("data/station_clusters.csv")
        df["sno"] = df["sno"].fillna("").astype(str)
        cluster_df["sno"] = cluster_df["sno"].fillna("").astype(str)
    except FileNotFoundError:
        st.warning(
            "å°šæœªç”¢ç”Ÿ station_clusters.csvï¼Œè«‹å…ˆåœ¨çµ‚ç«¯æ©ŸåŸ·è¡Œï¼š\n"
            "`python -m src.clustering`"
        )
    else:
        merged = df.merge(
            cluster_df[["sno", "cluster"]],
            on="sno",
            how="left",
        )

        cluster_ids = sorted(
            merged["cluster"].dropna().unique().tolist()
        )

        selected_cluster = st.selectbox(
            "é¸æ“‡è¦æŸ¥çœ‹çš„ cluster", options=cluster_ids
        )

        sub = merged[merged["cluster"] == selected_cluster].copy()
        st.write(f"Cluster {selected_cluster} â€” ç«™é»æ•¸ï¼š{len(sub)}")

        st.write("ç›®å‰ snapshot ç‹€æ…‹ï¼š")
        st.dataframe(
            sub[
                ["sarea", "sno", "sna", "rent", "return_count"]
            ].sort_values(["sarea", "sno"])
        )

        if not sub.empty:
            map_df = sub[
                ["lat", "lng", "sna", "rent", "return_count"]
            ].copy()
            map_df = map_df.rename(columns={"lng": "lon"})

            layer = pdk.Layer(
                "ScatterplotLayer",
                data=map_df,
                get_position="[lon, lat]",
                get_radius=60,
                pickable=True,
                get_fill_color="[50, 150, 255]",
                get_line_color=[0, 0, 0],
            )

            view_state = pdk.ViewState(
                latitude=map_df["lat"].mean(),
                longitude=map_df["lon"].mean(),
                zoom=12,
                pitch=0,
            )

            deck = pdk.Deck(
                layers=[layer],
                initial_view_state=view_state,
                tooltip={
                    "text": "{sna}\nå¯å€Ÿ: {rent}  å¯é‚„: {return_count}"
                },
            )

            st.pydeck_chart(deck)

# ======================================================
# PAGE 5 â€” Flow / Heatmap
# ======================================================
elif page == "ğŸ“ˆ Flow / Heatmap":
    st.subheader("ğŸ“ˆ æ—¥æµé‡è¶¨å‹¢ & ç†±é»åœ–ï¼ˆä¾å°æ™‚ / å€åŸŸï¼‰")

    START_HOUR = 6
    END_HOUR = 22

    flow_df = load_hourly_flow(START_HOUR, END_HOUR)
    if flow_df.empty:
        st.warning("æœ€è¿‘ 24 å°æ™‚å…§æ²’æœ‰è¶³å¤ è³‡æ–™å¯ä¾› Flow / Heatmap åˆ†æã€‚")
    else:
        # æ¨¡å¼åˆ‡æ›åœ¨ä¸»ç•«é¢ï¼Œä¸åœ¨ sidebarï¼ˆé¿å…é é¢è·³å›å»ï¼‰
        mode = st.radio(
            "æª¢è¦–æ¨¡å¼",
            ["Flowï¼ˆæŒ‡å®šç«™ï¼‰", "Heatmapï¼ˆå…¨éƒ¨å€åŸŸï¼‰"],
            horizontal=True,
        )

        # -------- Flowï¼šæŒ‡å®šç«™ --------
        if mode == "Flowï¼ˆæŒ‡å®šç«™ï¼‰":
            st.markdown("### æ‰‹å‹•é¸ç«™ Flowï¼ˆå¹³å‡å¯å€Ÿè»Šæ•¸ï¼‰")

            station_options = df.apply(
                lambda x: f"{x['sno']} - {x['sna']}", axis=1
            ).tolist()
            selected_stations = st.multiselect(
                "é¸æ“‡è¦çœ‹çš„ç«™é»ï¼ˆå»ºè­° 1â€“5 å€‹ï¼‰",
                options=station_options,
            )

            if selected_stations:
                selected_snos = [s.split(" - ")[0] for s in selected_stations]
                sub = flow_df[flow_df["sno"].isin(selected_snos)].copy()

                if sub.empty:
                    st.warning("é€™äº›ç«™åœ¨æœ€è¿‘ 24 å°æ™‚å…§æ²’æœ‰è³‡æ–™ã€‚")
                else:
                    sub["station_label"] = sub["sna"].fillna(sub["sno"])

                    fig_flow = px.line(
                        sub,
                        x="hour",
                        y="avg_rent",
                        color="station_label",
                        markers=True,
                        labels={
                            "hour": "Hour of Day",
                            "avg_rent": "Avg. Rent Bikes",
                            "station_label": "Station",
                        },
                    )
                    fig_flow.update_xaxes(dtick=1)
                    st.plotly_chart(fig_flow, width="stretch")
            else:
                st.info("è«‹è‡³å°‘é¸æ“‡ä¸€å€‹ç«™é»ä¾†çœ‹ Flowã€‚")

        # -------- Heatmapï¼šå…¨éƒ¨å€åŸŸï¼ˆRPIï¼‰ --------
        else:
            st.markdown("### å€åŸŸ x å°æ™‚ ç†±é»åœ–ï¼ˆè£œè»Šå£“åŠ›æŒ‡æ•¸ RPIï¼‰")

            # å…ˆå»æ‰æ¸¬è©¦ç”¨å€åŸŸï¼ˆä¿éšªï¼šFlow è³‡æ–™å¦‚æœé‚„ç•™ Test Area ä¹Ÿä¸€èµ·éæ¿¾ï¼‰
            area_df = (
                flow_df[flow_df["sarea"] != "Test Area"]
                .groupby(["sarea", "hour"], as_index=False)["rpi"]
                .mean()
            )

            if area_df.empty:
                st.warning("ç„¡æ³•ç”¢ç”Ÿç†±é»åœ–ï¼Œè³‡æ–™ä¸è¶³ã€‚")
            else:
                pivot = area_df.pivot(
                    index="sarea", columns="hour", values="rpi"
                ).fillna(0.0)

                cols = [
                    h
                    for h in range(START_HOUR, END_HOUR + 1)
                    if h in pivot.columns
                ]
                pivot = pivot[cols]

                fig_hm = px.imshow(
                    pivot,
                    aspect="auto",
                    labels=dict(
                        x="Hour of Day",
                        y="Area (sarea)",
                        color="RPI",
                    ),
                    origin="lower",
                    color_continuous_scale="RdBu_r",
                    zmin=-0.6,
                    zmax=0.6,
                )
                st.plotly_chart(fig_hm, width="stretch")